import os
import streamlit as st
from dotenv import load_dotenv
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_groq import ChatGroq
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.prompts import PromptTemplate

# ุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
load_dotenv()
DB_FAISS_PATH = "vectorstore/db_faiss"
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# ุชุนุฏูู RTL ููุบุฉ ุงูุนุฑุจูุฉ
st.markdown(
    """
    <style>
    html, body, .main {
        direction: rtl;
        text-align: right;
    }
    .st-chat-message > div {
        direction: rtl;
        text-align: right;
    }
    .stTextInput>div>input {
        direction: rtl;
        text-align: right;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ุชุญููู ูุงุนุฏุฉ FAISS
@st.cache_resource
def get_vectorstore():
    embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L12-v2")
    db = FAISS.load_local(DB_FAISS_PATH, embedding, allow_dangerous_deserialization=True)
    return db

# ูุงุฆูุฉ ุงูุชุญูุงุช
GREETINGS = ["ูุฑุญุจุง", "ุฃููุงู", "ุฃููุง", "ูุงู", "ุงูุณูุงู ุนูููู"]

# Prompt ููุจูุช ุงูุฐูู + ุณุคุงู ูุชุงุจุนุฉ
retrieval_prompt = PromptTemplate(
    input_variables=["context", "input"],
    template="""
ุฃูุช ูุณุงุนุฏ ุทุจู ุฐูู ุฌุฏูุงุ ุฏูููุ ููุทููุ ููุงุฏุฑ ุนูู ุงูููู ูุงูุชูุณูุฑ. ูููุชู:

1. ุฅุฐุง ูุงู ุงูุณุคุงู ุงูุทุจู ููุฌูุฏูุง ูู ุงูุณูุงู (context)ุ ุฃุฌุจ ุจุทุฑููุฉ ูุงุถุญุฉ ููููุนุฉุ ุญุชู ูู ูุงู ุงูุณุคุงู ูุฎุชุตุฑูุง ุฃู ุงุณุชุฎุฏู ูููุงุช ูุดุงุจูุฉ.
2. ุฅุฐุง ูู ููู ุงูุณุคุงู ููุฌูุฏูุง ูุตููุง ูู ุงููุณุชูุฏุงุชุ ุญุงูู ุดุฑุญ ุงูุฅุฌุงุจุฉ ุจุทุฑููุฉ ุนูููุฉ ูุขููุฉ ุจูุงุกู ุนูู ุงููุนุฑูุฉ ุงูุทุจูุฉ ุงูุนุงูุฉุ ูุน ุงูุฅุดุงุฑุฉ ุฅูู ุฃููุง ูู ุงููุนุฑูุฉ ุงูุนุงูุฉ ูููุณุช ูู ุงููุณุชูุฏุงุช.
3. ุงุฌุนู ุฅุฌุงุจุชู ูููููุฉ ูููุณุชุฎุฏู ุงูุนุงุฏูุ ูุตูุฑุฉ ููุงุถุญุฉ ููููุนุฉ.
4. ูุง ุชุฎุชูู ูุนูููุงุช ุฎุทูุฑุฉ ุฃู ูุถููุฉ.
5. ุจุนุฏ ูู ุฅุฌุงุจุฉุ ุงูุชุฑุญ ุณุคุงู ูุชุงุจุนุฉ ุทุจู ูุตูุฑ ูููุงุฆู ูููุณุชุฎุฏู.
6. ุฅุฐุง ูู ุชุนุฑู ุงูุฅุฌุงุจุฉุ ุฃุฌุจ: "ูุง ุชูุฌุฏ ูุนูููุงุช ูุชุงุญุฉ ูู ุงููุณุชูุฏุงุช ุฃู ุงููุนุฑูุฉ ุงูุทุจูุฉ ุงูุนุงูุฉ".

ุงูุณูุงู (ุงููุณุชูุฏุงุช):
{context}

ุณุคุงู ุงููุณุชุฎุฏู:
{input}

ุฅุฌุงุจุฉ (ูุน ุงูุชุฑุงุญ ุณุคุงู ูุชุงุจุนุฉ ูู ุงูููุงูุฉ):
"""
)

def main():
    st.title("๐ค ูุณุงุนุฏู ุงูุทุจู ุงูุฐูู")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ุนุฑุถ ุงููุญุงุฏุซุงุช ุงูุณุงุจูุฉ
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).markdown(msg["content"])

    user_prompt = st.chat_input("ุงูุชุจ ุณุคุงูู ุฃู ุชุญูุชู ููุง...")
    if user_prompt:
        st.chat_message("user").markdown(user_prompt)
        st.session_state.messages.append({"role": "user", "content": user_prompt})

        # ุงูุฑุฏ ุนูู ุงูุชุญูุงุช ุจุดูู ููุงุณุจ
        if "ุตุจุงุญ ุงูุฎูุฑ" in user_prompt:
            greeting_reply = "ุตุจุงุญ ุงูููุฑ! ููู ูููููู ูุณุงุนุฏุชู ุงููููุ"
        elif "ูุณุงุก ุงูุฎูุฑ" in user_prompt:
            greeting_reply = "ูุณุงุก ุงูููุฑ! ููู ูููููู ูุณุงุนุฏุชู ุงููููุ"
        elif any(greet in user_prompt for greet in GREETINGS):
            greeting_reply = "ูุฑุญุจุง! ููู ูููููู ูุณุงุนุฏุชู ุงููููุ"
        else:
            greeting_reply = None

        if greeting_reply:
            st.chat_message("assistant").markdown(greeting_reply)
            st.session_state.messages.append({"role": "assistant", "content": greeting_reply})
        else:
            try:
                db = get_vectorstore()
                llm = ChatGroq(
                    model="llama-3.1-8b-instant",
                    temperature=0.0,
                    max_tokens=512,
                    api_key=GROQ_API_KEY
                )

                # ุฅูุดุงุก ุณูุณูุฉ RAG ูุน ุงูุจุญุซ ุงูููุณุน
                combine_chain = create_stuff_documents_chain(llm, retrieval_prompt)
                rag_chain = create_retrieval_chain(db.as_retriever(search_kwargs={"k": 10}), combine_chain)

                # ุงุณุชุฏุนุงุก RAG
                result = rag_chain.invoke({"input": user_prompt})

                # ุงุณุชุฎุฑุงุฌ ุงููุต ุงููุนูู ููุท
                if isinstance(result, dict):
                    answer = result.get("output_text") or result.get("text")
                elif hasattr(result, "content"):
                    answer = result.content
                else:
                    answer = str(result)

                # ุฅุฐุง ูู ุชูุฌุฏ ูุชูุฌุฉ ูู PDF โ ูุณุชุฎุฏู LLM ูููุนุฑูุฉ ุงูุนุงูุฉ
                if not answer or "ูุง ุชูุฌุฏ ูุนูููุงุช ูุชุงุญุฉ" in answer:
                    llm_response = llm.invoke(
                        f"ุฃุฌุจ ุนูู ุงูุณุคุงู ุงูุทุจู ุงูุชุงูู ุจุทุฑููุฉ ุนูููุฉ ููุงุถุญุฉ ูููุณุชุฎุฏู ุงูุนุงุฏู. "
                        f"ุฅุฐุง ูู ุชุนุฑู ุงูุฅุฌุงุจุฉ ุจุฏูุฉุ ุฃุฌุจ 'ูุง ุชูุฌุฏ ูุนูููุงุช ูุชุงุญุฉ': {user_prompt}"
                    )
                    if hasattr(llm_response, "content"):
                        answer = llm_response.content
                    else:
                        answer = str(llm_response)
                    answer = f"ููุงุญุธุฉ: ูุฐู ุงููุนูููุงุช ูู ุงููุนุฑูุฉ ุงูุนุงูุฉ. {answer}"

                # ุนุฑุถ ุงูุฅุฌุงุจุฉ
                st.chat_message("assistant").markdown(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer})

            except Exception as e:
                st.error(f"โ ุฎุทุฃ: {str(e)}")

if __name__ == "__main__":
    main()
